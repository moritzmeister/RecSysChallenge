{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse as sps\n",
    "import scipy.io as io\n",
    "import time\n",
    "import json\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to save a csr sparse matrix\n",
    "def save_sparse_csr(filename,array):\n",
    "    np.savez(filename,data = array.data ,indices=array.indices,\n",
    "             indptr =array.indptr, shape=array.shape )\n",
    "\n",
    "# function to read written csr sparse matrix\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return sp.csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                          shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RecommenderSystem(object):\n",
    "    \n",
    "    def __init__(self, interactions_file = '../input/train_final.csv', \n",
    "                       target_playlists = '../input/target_playlists.csv', \n",
    "                       target_tracks = '../input/target_tracks.csv',\n",
    "                       meta_track = '../input/tracks_final.csv'):\n",
    "        # read interactions file\n",
    "        train_final = pd.read_csv(interactions_file, sep = '\\t')\n",
    "        train_final['interaction'] = 1.0\n",
    "        self.df_interactions = train_final.sort_values(['playlist_id', 'track_id'], ascending=[True, True])\n",
    "        self.numInteractions = train_final.shape[0]\n",
    "        print(\"Number of interactions (numInteractions): \" + str(self.numInteractions))\n",
    "        \n",
    "        # read target playlists which should receive a recommendation\n",
    "        self.df_target_playlists = pd.read_csv(target_playlists, sep = '\\t')\n",
    "        self.list_target_playlists = list(self.df_target_playlists['playlist_id'])\n",
    "        print(\"Size of df_target_playlists: \" + str(self.df_target_playlists.shape))\n",
    "        \n",
    "        # read target tracks\n",
    "        self.df_target_tracks = pd.read_csv(target_tracks, sep = '\\t')\n",
    "        self.list_target_tracks = list(self.df_target_tracks['track_id'])\n",
    "        print(\"Size of df_target_tracks file: \" + str(self.df_target_tracks.shape))\n",
    "        print(\"Size of list_target_tracks file: \" + str(len(self.df_target_tracks)))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # separate each column in list\n",
    "        playlist_id = list(self.df_interactions['playlist_id'])\n",
    "        track_id = list(self.df_interactions['track_id'])\n",
    "        interaction = list(self.df_interactions['interaction'])\n",
    "        \n",
    "        playlist_id_unique = list(set(playlist_id))\n",
    "        self.df_playlist_id_unique = pd.DataFrame(playlist_id_unique)\n",
    "        self.df_playlist_id_unique.reset_index(level=0, inplace=True)\n",
    "        self.df_playlist_id_unique.columns = ['index_playlist', 'playlist_id']\n",
    "        \n",
    "        track_id_unique = list(set(track_id))\n",
    "        self.df_track_id_unique = pd.DataFrame(track_id_unique)\n",
    "        self.df_track_id_unique.reset_index(level=0, inplace=True)\n",
    "        self.df_track_id_unique.columns = ['index_track', 'track_id']\n",
    "        print(\"Track_id translated to indexes (df_track_id_unique): \")\n",
    "        print(self.df_track_id_unique.head())\n",
    "        print(\"\\n\")\n",
    "        print(\"Playlist_id translated to indexes (df_playlist_id_unique): \")\n",
    "        print(self.df_playlist_id_unique.head())\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        self.numPlaylists = len(self.df_playlist_id_unique)\n",
    "        self.numTracks = len(self.df_track_id_unique)\n",
    "        print(\"Number of Playlists: \" + str(self.numPlaylists))\n",
    "        print(\"Number of Tracks: \" + str(self.numTracks))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        self.df_interactions = self.df_interactions.merge(self.df_playlist_id_unique, how='inner', on='playlist_id')\n",
    "        self.df_interactions = self.df_interactions.merge(self.df_track_id_unique, how='inner', on='track_id')\n",
    "        self.df_interactions = self.df_interactions.sort_values(['playlist_id', 'track_id'], ascending=[True, True])\n",
    "        print(\"Interactions-file with IDs translated to indexes (saved in df_interactions): \")\n",
    "        print(self.df_interactions.head())\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        self.list_index_playlist = np.array(self.df_interactions['index_playlist'])\n",
    "        self.list_index_track = np.array(self.df_interactions['index_track'])\n",
    "        self.list_interactions = np.array(self.df_interactions['interaction'])\n",
    "        \n",
    "        self.df_tracks = pd.read_csv(meta_track, sep = '\\t')\n",
    "        self.df_tracks = self.df_tracks.merge(self.df_track_id_unique, how='inner', on='track_id')\n",
    "        self.df_tracks['tags'] = self.df_tracks.tags.apply(json.loads)\n",
    "        self.df_tracks['album'] = self.df_tracks.album.apply(lambda x: (str(x[1:-1]) + \"a\") if x != \"[None]\" and x != \"[]\" else \"-10a\")\n",
    "        print('Meta information about tracks read (df_tracks): ')\n",
    "        print(self.df_tracks.head())\n",
    "        print(self.df_tracks.shape)\n",
    "        \n",
    "    def target_structure(self):\n",
    "        # filter interaction dataframe, to retain only target playlists\n",
    "        train = self.df_interactions.merge(self.df_target_playlists, how='inner', on='playlist_id')\n",
    "        \n",
    "        # aggregate to playlist level and coerce tracks in that playlist to list\n",
    "        train_agg1 = train.groupby(by='playlist_id').track_id.apply(list).to_frame()\n",
    "        train_agg1.reset_index(level=0, inplace=True)\n",
    "        train_agg2 = train.groupby(by='playlist_id').index_track.apply(list).to_frame()\n",
    "        train_agg2.reset_index(level=0, inplace=True)\n",
    "        train_agg = train_agg1.merge(train_agg2, how='inner', on='playlist_id')\n",
    "        self.df_target = train_agg.merge(self.df_playlist_id_unique, how='inner', on='playlist_id')\n",
    "        self.df_target['recommend'] = np.empty((len(train_agg), 0)).tolist()\n",
    "        print(\"Data structure for final prediction was created (df_target): \")\n",
    "        print(self.df_target.head())\n",
    "        print(self.df_target.shape)\n",
    "        \n",
    "    def interaction_aggregation(self):\n",
    "        \n",
    "        agg1 = self.df_interactions.groupby(by='playlist_id').track_id.apply(list).to_frame()\n",
    "        agg1.reset_index(level=0, inplace=True)\n",
    "        agg2 = self.df_interactions.groupby(by='playlist_id').index_track.apply(list).to_frame()\n",
    "        agg2.reset_index(level=0, inplace=True)\n",
    "        agg3 = self.df_interactions.groupby(by='playlist_id').nunique()\n",
    "        agg3.reset_index(level=0, inplace=True)\n",
    "        agg = agg1.merge(agg2, how='inner', on='playlist_id')\n",
    "        agg = agg.merge(agg3, how='inner', on='playlist_id')\n",
    "        print(agg[:10])\n",
    "        \n",
    "    def create_uim(self, sparse_mode=\"coo\", create_testset = False, split = 0.8):\n",
    "        if sparse_mode.lower() == \"coo\" or sparse_mode.lower() == \"csr\":\n",
    "            self.UIM = sps.coo_matrix((self.list_interactions, (self.list_index_playlist, self.list_index_track)))\n",
    "            if create_testset:\n",
    "                self.split_traintest(train_test_split = split)\n",
    "            if sparse_mode.lower() == \"csr\" and create_testset != True:\n",
    "                self.UIM = self.UIM.tocsr()\n",
    "            elif sparse_mode.lower() == \"csr\" and create_testset == True:\n",
    "                self.UIM = self.UIM.tocsr()\n",
    "                self.UIM_train = self.UIM_train.tocsr()\n",
    "                self.UIM_test = self.UIM_test.tocsr()\n",
    "                \n",
    "        else:\n",
    "            raise NotImplementedError('Sparse mode not implemented'.format(sparse_mode))\n",
    "            \n",
    "    def split_traintest(self, train_test_split):\n",
    "        train_mask = np.random.choice([True,False], self.numInteractions, p=[train_test_split, 1-train_test_split])\n",
    "        test_mask = np.logical_not(train_mask)\n",
    "        self.UIM_train = sps.coo_matrix((self.list_interactions[train_mask], \n",
    "                                        (self.list_index_playlist[train_mask], \n",
    "                                         self.list_index_track[train_mask])))\n",
    "        self.UIM_test = sps.coo_matrix((self.list_interactions, (self.list_index_playlist, self.list_index_track)))\n",
    "        print(\"UIM successfully created in csr format.\")\n",
    "        \n",
    "    def create_icm(self, include_tags = True, include_album = True, include_artist = True, include_playcount = False, include_duration = False, playcount_bins = 50, duration_bins = 3):\n",
    "        tags_list = []\n",
    "        \n",
    "        if include_playcount:\n",
    "            cbf.df_tracks['playcount'].fillna(0, inplace = True)\n",
    "            cbf.df_tracks['playcount_bin'] = pd.qcut(cbf.df_tracks['playcount'], playcount_bins, duplicates = 'drop').astype('str')\n",
    "        if include_duration:\n",
    "            cbf.df_tracks['duration_bin'] = pd.qcut(cbf.df_tracks['duration'], duration_bins, duplicates = 'drop').astype('str')\n",
    "            \n",
    "        for index, row in self.df_tracks.iterrows():\n",
    "            if len(row['tags']) != 0 and include_tags:\n",
    "                for i in row['tags']:\n",
    "                    tags_list.append([row['index_track'], i, 1.0])\n",
    "            if row['album'] != \"-10a\" and include_album:\n",
    "                tags_list.append([row['index_track'], row['album'], 1])\n",
    "            if include_artist:\n",
    "                tags_list.append([row['index_track'], str(row['artist_id']) + \"b\", 1.0])\n",
    "            if include_playcount:\n",
    "                tags_list.append([row['index_track'], row['playcount_bin'] + \"x\", 1.0])\n",
    "            if include_duration and row['duration'] != -1:\n",
    "                tags_list.append([row['index_track'], row['duration_bin'] + \"z\", 1.0])\n",
    "        tags_list = pd.DataFrame(tags_list)\n",
    "        tags_list.columns = ['index_track', 'tag', 'interaction']\n",
    "        track_list = list(tags_list['index_track'])\n",
    "        tag_list = list(tags_list['tag'])\n",
    "        self.final_taglist = list(tags_list['tag'])\n",
    "        interaction_list = list(tags_list['interaction'])\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(tag_list)\n",
    "        taglist_icm = le.transform(tag_list)\n",
    "        self.ICM = sps.coo_matrix((interaction_list, (track_list, taglist_icm)))\n",
    "        self.ICM = self.ICM.tocsr()\n",
    "        # append playcount and duration\n",
    "        # if include_playcount:\n",
    "        #     self.df_tracks['playcount'].fillna(0, inplace = True)\n",
    "        #     self.ICM = sps.hstack((self.ICM, self.df_tracks[['index_track', 'playcount']].sort_values(by = 'index_track')['playcount'].values[:,None]))\n",
    "        #     if include_duration:\n",
    "        #         self.ICM = sps.hstack((self.ICM, self.df_tracks[['index_track', 'duration']].sort_values(by = 'index_track')['duration'].values[:,None]))\n",
    "        #     self.ICM = self.ICM.tocsr()\n",
    "        print(\"ICM successfully created in csr format.\")\n",
    "        \n",
    "    def td_idf(self, ICM):\n",
    "        '''Applies TD-IDF to the ICM Matrix of the RecommenderSystem Instance'''\n",
    "        \n",
    "        num_tot_items = ICM.shape[0]\n",
    "\n",
    "        # let's count how many items have a certain feature\n",
    "        items_per_feature = (ICM > 0).sum(axis=0)\n",
    "        \n",
    "        IDF = np.array(np.log(num_tot_items / items_per_feature))[0]\n",
    "        \n",
    "        print(\"Shape of IDF\")\n",
    "        print(IDF.shape)\n",
    "        \n",
    "        ICM_idf = ICM.copy()\n",
    "        # compute the number of non-zeros in each col\n",
    "        # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "        col_nnz = np.diff(check_matrix(ICM_idf, 'csc').indptr)\n",
    "        print(\"Shape of ICM_idf\")\n",
    "        print(ICM_idf.shape)\n",
    "        # then normalize the values in each col\n",
    "        ICM_idf.data *= np.repeat(IDF, col_nnz)\n",
    "        \n",
    "        return ICM_idf\n",
    "        \n",
    "    def svd(self, matrix, k = 100):\n",
    "        \n",
    "        U, s, Vt = svds(matrix, k)\n",
    "        s_diag = np.diag(s)\n",
    "        Us = np.dot(U, s_diag)\n",
    "        return sps.csr_matrix(np.dot(Us, Vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BasicItemKNNRecommender(RecommenderSystem):\n",
    "       \n",
    "    def __str__(self):\n",
    "        return \"ItemKNN(similarity={},k={},shrinkage={})\".format(self.similarity_name, self.k, self.shrinkage)\n",
    "    \n",
    "    def fit(self, shrinkage=100, similarity='cosine', apply_td_idf = False, apply_svd_icm = False, k=100,\n",
    "            include_tags = True, include_album = True, include_artist = True, \n",
    "            include_playcount = False, include_duration = False, playcount_bins = 50, duration_bins = 3):\n",
    "        self.shrinkage = shrinkage\n",
    "        self.similarity_name = similarity\n",
    "        if similarity == 'cosine':\n",
    "            self.distance = Cosine(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'pearson':\n",
    "            self.distance = Pearson(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'adj-cosine':\n",
    "            self.distance = AdjustedCosine(shrinkage=self.shrinkage)\n",
    "        else:\n",
    "            raise NotImplementedError('Distance {} not implemented'.format(similarity))\n",
    "        \n",
    "        self.create_uim(sparse_mode = 'csr')\n",
    "        self.create_icm(include_tags, include_album, include_artist, include_playcount, include_duration, playcount_bins, duration_bins)\n",
    "        \n",
    "        if apply_svd_icm and not apply_td_idf:\n",
    "            self.ICM_estm = self.svd(self.ICM, k)\n",
    "            print(\"ICM_estm computed:\")\n",
    "            print(self.ICM_estm.shape)\n",
    "            item_weights = self.distance.compute(self.ICM_estm)\n",
    "        elif apply_td_idf:\n",
    "            self.ICM_idf = self.td_idf(self.ICM)\n",
    "            item_weights = self.distance.compute(self.ICM_idf)\n",
    "        elif apply_svd_icm and apply_td_idf:\n",
    "            self.ICM_estm = self.svd(self.ICM, k)\n",
    "            print(\"ICM_estm computed:\")\n",
    "            print(ICM_estm.shape)\n",
    "            self.ICM_IDF = self.td_idf(self.ICM_estm)\n",
    "            item_weights = self.distance.compute(self.ICM_idf)\n",
    "        else:\n",
    "            item_weights = self.distance.compute(self.ICM)\n",
    "        \n",
    "        item_weights = check_matrix(item_weights, 'csr') # nearly 10 times faster\n",
    "        print(\"Converted to csr\")\n",
    "        \n",
    "        self.W = item_weights\n",
    "        self.UIM_estm = self.UIM.dot(self.W)\n",
    "        print('UIM_estm calculated')\n",
    "        \n",
    "    def fit_svd(self, shrinkage=100, similarity='cosine', apply_td_idf = False, apply_svd_icm = False, k=100,\n",
    "            include_tags = True, include_album = True, include_artist = True, \n",
    "            include_playcount = False, include_duration = False, playcount_bins = 50, duration_bins = 3):\n",
    "        self.shrinkage = shrinkage\n",
    "        self.similarity_name = similarity\n",
    "        if similarity == 'cosine':\n",
    "            self.distance = Cosine(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'pearson':\n",
    "            self.distance = Pearson(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'adj-cosine':\n",
    "            self.distance = AdjustedCosine(shrinkage=self.shrinkage)\n",
    "        else:\n",
    "            raise NotImplementedError('Distance {} not implemented'.format(similarity))\n",
    "        \n",
    "        self.create_uim(sparse_mode = 'csr')\n",
    "        self.create_icm(include_tags, include_album, include_artist, include_playcount, include_duration, playcount_bins, duration_bins)\n",
    "        \n",
    "        if apply_svd_icm and not apply_td_idf:\n",
    "            self.ICM_estm = self.svd(self.ICM, k)\n",
    "            print(\"ICM_estm computed:\")\n",
    "            print(self.ICM_estm.shape)\n",
    "            item_weights = self.distance.compute(self.ICM_estm)\n",
    "        elif apply_td_idf:\n",
    "            self.ICM_idf = self.td_idf(self.ICM)\n",
    "            item_weights = self.distance.compute(self.ICM_idf)\n",
    "        elif apply_svd_icm and apply_td_idf:\n",
    "            self.ICM_estm = self.svd(self.ICM, k)\n",
    "            print(\"ICM_estm computed:\")\n",
    "            print(ICM_estm.shape)\n",
    "            self.ICM_IDF = self.td_idf(self.ICM_estm)\n",
    "            item_weights = self.distance.compute(self.ICM_idf)\n",
    "        else:\n",
    "            item_weights = self.distance.compute(self.ICM)\n",
    "        \n",
    "        item_weights = check_matrix(item_weights, 'csr') # nearly 10 times faster\n",
    "        print(\"Converted to csr\")\n",
    "        \n",
    "        self.W = item_weights\n",
    "        UIM_svd = self.svd(self.UIM, k)\n",
    "        print(\"SVD calculated\")\n",
    "        self.UIM_estm = self.UIM_svd.dot(self.W)\n",
    "        print('UIM_estm calculated')\n",
    "\n",
    "    def recommend(self, at=5):\n",
    "        self.target_structure()\n",
    "        start_time = time.time()\n",
    "        for index, row in self.df_target.iterrows():          \n",
    "            #get row from URM_estm\n",
    "            estm = pd.DataFrame(self.UIM_estm[row['index_playlist'],:].T.toarray())\n",
    "            estm.reset_index(level=0, inplace=True)\n",
    "            estm.columns = ['index_track','pred']\n",
    "            # filter tracks which are already in the playlist, so they can't be recommended\n",
    "            estm = estm[-estm[\"index_track\"].isin(row['index_track'])]\n",
    "            # translate track index back to track_id\n",
    "            estm = estm.merge(self.df_track_id_unique, how='inner', on='index_track')\n",
    "            # filter on target track set\n",
    "            estm = estm[estm['track_id'].isin(self.list_target_tracks)]\n",
    "            estm = estm.sort_values('pred',ascending=False)\n",
    "            # print(estm)\n",
    "            count = 1\n",
    "            for index2, row2 in estm.iterrows():\n",
    "                # insert 5 top recommendations into dataframe\n",
    "                if count < (at + 1):\n",
    "                    row['recommend'].append(int(row2['track_id']))\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break\n",
    "        print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))\n",
    "        \n",
    "def check_matrix(X, format='csc', dtype=np.float32):\n",
    "    if format == 'csc' and not isinstance(X, sps.csc_matrix):\n",
    "        return X.tocsc().astype(dtype)\n",
    "    elif format == 'csr' and not isinstance(X, sps.csr_matrix):\n",
    "        return X.tocsr().astype(dtype)\n",
    "    elif format == 'coo' and not isinstance(X, sps.coo_matrix):\n",
    "        return X.tocoo().astype(dtype)\n",
    "    elif format == 'dok' and not isinstance(X, sps.dok_matrix):\n",
    "        return X.todok().astype(dtype)\n",
    "    elif format == 'bsr' and not isinstance(X, sps.bsr_matrix):\n",
    "        return X.tobsr().astype(dtype)\n",
    "    elif format == 'dia' and not isinstance(X, sps.dia_matrix):\n",
    "        return X.todia().astype(dtype)\n",
    "    elif format == 'lil' and not isinstance(X, sps.lil_matrix):\n",
    "        return X.tolil().astype(dtype)\n",
    "    else:\n",
    "        return X.astype(dtype)\n",
    "    \n",
    "class ISimilarity(object):\n",
    "    \"\"\"Abstract interface for the similarity metrics\"\"\"\n",
    "\n",
    "    def __init__(self, shrinkage=10):\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "    def compute(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Cosine(ISimilarity):\n",
    "    def compute(self, X):\n",
    "        # convert to csc matrix for faster column-wise operations\n",
    "        X = check_matrix(X, 'csc', dtype=np.float32)\n",
    "\n",
    "        # 1) normalize the columns in X\n",
    "        # compute the column-wise norm\n",
    "        # NOTE: this is slightly inefficient. We must copy X to compute the column norms.\n",
    "        # A faster solution is to  normalize the matrix inplace with a Cython function.\n",
    "        Xsq = X.copy()\n",
    "        Xsq.data **= 2\n",
    "        norm = np.sqrt(Xsq.sum(axis=0))\n",
    "        norm = np.asarray(norm).ravel()\n",
    "        norm += 1e-6\n",
    "        # compute the number of non-zeros in each column\n",
    "        # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "        col_nnz = np.diff(X.indptr)\n",
    "        # then normalize the values in each column\n",
    "        X.data /= np.repeat(norm, col_nnz)\n",
    "        print(\"Normalized\")\n",
    "\n",
    "        # 2) compute the cosine similarity using the dot-product\n",
    "        dist = X * X.T\n",
    "        print(\"Computed\")\n",
    "        \n",
    "        # zero out diagonal values\n",
    "        dist = dist - sps.dia_matrix((dist.diagonal()[sp.newaxis, :], [0]), shape=dist.shape)\n",
    "        print(\"Removed diagonal\")\n",
    "        \n",
    "        # and apply the shrinkage\n",
    "        if self.shrinkage > 0:\n",
    "            dist = self.apply_shrinkage(X, dist)\n",
    "            print(\"Applied shrinkage\")    \n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def apply_shrinkage(self, X, dist):\n",
    "        # create an \"indicator\" version of X (i.e. replace values in X with ones)\n",
    "        X_ind = X.copy()\n",
    "        X_ind.data = np.ones_like(X_ind.data)\n",
    "        # compute the co-rated counts\n",
    "        co_counts = X_ind * X_ind.T\n",
    "        # remove the diagonal\n",
    "        co_counts = co_counts - sps.dia_matrix((co_counts.diagonal()[sp.newaxis, :], [0]), shape=co_counts.shape)\n",
    "        # compute the shrinkage factor as co_counts_ij / (co_counts_ij + shrinkage)\n",
    "        # then multiply dist with it\n",
    "        co_counts_shrink = co_counts.copy()\n",
    "        co_counts_shrink.data += self.shrinkage\n",
    "        co_counts.data /= co_counts_shrink.data\n",
    "        dist.data *= co_counts.data\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interactions (numInteractions): 1040522\n",
      "Size of df_target_playlists: (10000, 1)\n",
      "Size of df_target_tracks file: (32195, 1)\n",
      "Size of list_target_tracks file: 32195\n",
      "\n",
      "\n",
      "Track_id translated to indexes (df_track_id_unique): \n",
      "   index_track  track_id\n",
      "0            0   1048594\n",
      "1            1   2359314\n",
      "2            2   1835030\n",
      "3            3   3670041\n",
      "4            4   1048604\n",
      "\n",
      "\n",
      "Playlist_id translated to indexes (df_playlist_id_unique): \n",
      "   index_playlist  playlist_id\n",
      "0               0     10485762\n",
      "1               1      5767174\n",
      "2               2      7077894\n",
      "3               3     11534344\n",
      "4               4      1179658\n",
      "\n",
      "\n",
      "Number of Playlists: 45649\n",
      "Number of Tracks: 99999\n",
      "\n",
      "\n",
      "Interactions-file with IDs translated to indexes (saved in df_interactions): \n",
      "     playlist_id  track_id  interaction  index_playlist  index_track\n",
      "0           7569    162463          1.0            2425        62358\n",
      "87          7569    421750          1.0            2425        60999\n",
      "116         7569    795606          1.0            2425         3009\n",
      "125         7569   1195736          1.0            2425        55563\n",
      "195         7569   2227105          1.0            2425        49116\n",
      "\n",
      "\n",
      "Meta information about tracks read (df_tracks): \n",
      "   track_id  artist_id  duration  playcount album  \\\n",
      "0   2972914        144    224000       49.0    7a   \n",
      "1   2750239        246    157000        1.0    8a   \n",
      "2   1550729        144    217000      554.0    9a   \n",
      "3   2169950        144    207000      200.0    9a   \n",
      "4   1903709        144    198000        5.0  -10a   \n",
      "\n",
      "                                     tags  index_track  \n",
      "0     [54087, 1757, 1718, 116712, 189631]        33328  \n",
      "1   [189631, 3424, 177424, 46208, 205245]        48728  \n",
      "2   [54087, 109806, 46869, 183258, 54337]        93035  \n",
      "3  [54087, 70618, 207003, 109806, 116712]        26668  \n",
      "4   [54087, 81223, 116712, 215342, 71028]        25248  \n",
      "(99999, 7)\n"
     ]
    }
   ],
   "source": [
    "cbf = BasicItemKNNRecommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cbf.create_uim(sparse_mode = 'csr')\n",
    "cbf.UIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UIM_svd = cbf.svd(cbf.UIM, k = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cbf.fit(shrinkage=65, apply_td_idf = False, apply_svd_icm = False, k = 50, include_playcount = False, include_duration = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICM successfully created in csr format.\n",
      "Normalized\n",
      "Computed\n"
     ]
    }
   ],
   "source": [
    "cbf.fit_svd(shrinkage = 50, k = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(cbf.ICM_estm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cbf.recommend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cbf.df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert list to string with spaces between track_ids\n",
    "cbf.df_target['recommend'] = cbf.df_target['recommend'].apply(lambda x: \" \".join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rename columns for submission\n",
    "final = cbf.df_target[['playlist_id','recommend']]\n",
    "final.columns = ['playlist_id','track_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export file\n",
    "final.to_csv('../submission/005_cbf_s65_albumartist.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cbf.UIM_estm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use self defined function\n",
    "save_sparse_csr('../output/005_cbf_s50_W', cbf.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calcualte singular value decomposition\n",
    "start_time = time.time()\n",
    "U, s, Vt = svds(URM_all, k = 252)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# make diagonal matrix from sigma values\n",
    "s_diag = np.diag(s)\n",
    "\n",
    "# reconstruct URM matrix as prediction\n",
    "Us = np.dot(U, s_diag)\n",
    "Us.shape\n",
    "\n",
    "# reconstruct URM matrix as prediction\n",
    "start_time = time.time()\n",
    "URM_estm = np.dot(Us, Vt)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
