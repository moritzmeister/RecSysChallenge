{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse as sps\n",
    "import scipy.io as io\n",
    "import time\n",
    "import json\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RecommenderSystem(object):\n",
    "    \n",
    "    def __init__(self, interactions_file = '../input/train_final.csv', \n",
    "                       target_playlists = '../input/target_playlists.csv', \n",
    "                       target_tracks = '../input/target_tracks.csv',\n",
    "                       meta_track = '../input/tracks_final.csv'):\n",
    "        # read interactions file\n",
    "        train_final = pd.read_csv(interactions_file, sep = '\\t')\n",
    "        train_final['interaction'] = 1\n",
    "        self.df_interactions = train_final.sort_values(['playlist_id', 'track_id'], ascending=[True, True])\n",
    "        self.numInteractions = train_final.shape[0]\n",
    "        print(\"Number of interactions (numInteractions): \" + str(self.numInteractions))\n",
    "        \n",
    "        # read target playlists which should receive a recommendation\n",
    "        self.df_target_playlists = pd.read_csv(target_playlists, sep = '\\t')\n",
    "        self.list_target_playlists = list(self.df_target_playlists['playlist_id'])\n",
    "        print(\"Size of df_target_playlists: \" + str(self.df_target_playlists.shape))\n",
    "        \n",
    "        # read target tracks\n",
    "        self.df_target_tracks = pd.read_csv(target_tracks, sep = '\\t')\n",
    "        self.list_target_tracks = list(self.df_target_tracks['track_id'])\n",
    "        print(\"Size of df_target_tracks file: \" + str(self.df_target_tracks.shape))\n",
    "        print(\"Size of list_target_tracks file: \" + str(len(self.df_target_tracks)))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # separate each column in list\n",
    "        playlist_id = list(self.df_interactions['playlist_id'])\n",
    "        track_id = list(self.df_interactions['track_id'])\n",
    "        interaction = list(self.df_interactions['interaction'])\n",
    "        \n",
    "        playlist_id_unique = list(set(playlist_id))\n",
    "        self.df_playlist_id_unique = pd.DataFrame(playlist_id_unique)\n",
    "        self.df_playlist_id_unique.reset_index(level=0, inplace=True)\n",
    "        self.df_playlist_id_unique.columns = ['index_playlist', 'playlist_id']\n",
    "        \n",
    "        track_id_unique = list(set(track_id))\n",
    "        self.df_track_id_unique = pd.DataFrame(track_id_unique)\n",
    "        self.df_track_id_unique.reset_index(level=0, inplace=True)\n",
    "        self.df_track_id_unique.columns = ['index_track', 'track_id']\n",
    "        print(\"Track_id translated to indexes (df_track_id_unique): \")\n",
    "        print(self.df_track_id_unique.head())\n",
    "        print(\"\\n\")\n",
    "        print(\"Playlist_id translated to indexes (df_playlist_id_unique): \")\n",
    "        print(self.df_playlist_id_unique.head())\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        self.numPlaylists = len(self.df_playlist_id_unique)\n",
    "        self.numTracks = len(self.df_track_id_unique)\n",
    "        print(\"Number of Playlists: \" + str(self.numPlaylists))\n",
    "        print(\"Number of Tracks: \" + str(self.numTracks))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        self.df_interactions = self.df_interactions.merge(self.df_playlist_id_unique, how='inner', on='playlist_id')\n",
    "        self.df_interactions = self.df_interactions.merge(self.df_track_id_unique, how='inner', on='track_id')\n",
    "        self.df_interactions = self.df_interactions.sort_values(['playlist_id', 'track_id'], ascending=[True, True])\n",
    "        print(\"Interactions-file with IDs translated to indexes (saved in df_interactions): \")\n",
    "        print(self.df_interactions.head())\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        self.list_index_playlist = np.array(self.df_interactions['index_playlist'])\n",
    "        self.list_index_track = np.array(self.df_interactions['index_track'])\n",
    "        self.list_interactions = np.array(self.df_interactions['interaction'])\n",
    "        \n",
    "        self.df_tracks = pd.read_csv(meta_track, sep = '\\t')\n",
    "        self.df_tracks = self.df_tracks.merge(self.df_track_id_unique, how='inner', on='track_id')\n",
    "        self.df_tracks['tags'] = self.df_tracks.tags.apply(json.loads)\n",
    "        print('Meta information about tracks read (df_tracks): ')\n",
    "        print(self.df_tracks.head())\n",
    "        print(self.df_tracks.shape)\n",
    "        \n",
    "    def target_structure(self):\n",
    "        # filter interaction dataframe, to retain only target playlists\n",
    "        train = self.df_interactions.merge(self.df_target_playlists, how='inner', on='playlist_id')\n",
    "        \n",
    "        # aggregate to playlist level and coerce tracks in that playlist to list\n",
    "        train_agg1 = train.groupby(by='playlist_id').track_id.apply(list).to_frame()\n",
    "        train_agg1.reset_index(level=0, inplace=True)\n",
    "        train_agg2 = train.groupby(by='playlist_id').index_track.apply(list).to_frame()\n",
    "        train_agg2.reset_index(level=0, inplace=True)\n",
    "        train_agg = train_agg1.merge(train_agg2, how='inner', on='playlist_id')\n",
    "        self.df_target = train_agg.merge(self.df_playlist_id_unique, how='inner', on='playlist_id')\n",
    "        self.df_target['recommend'] = np.empty((len(train_agg), 0)).tolist()\n",
    "        print(\"Data structure for final prediction was created (df_target): \")\n",
    "        print(self.df_target.head())\n",
    "        print(self.df_target.shape)\n",
    "        \n",
    "    def interaction_aggregation(self):\n",
    "        \n",
    "        agg1 = self.df_interactions.groupby(by='playlist_id').track_id.apply(list).to_frame()\n",
    "        agg1.reset_index(level=0, inplace=True)\n",
    "        agg2 = self.df_interactions.groupby(by='playlist_id').index_track.apply(list).to_frame()\n",
    "        agg2.reset_index(level=0, inplace=True)\n",
    "        agg3 = self.df_interactions.groupby(by='playlist_id').nunique()\n",
    "        agg3.reset_index(level=0, inplace=True)\n",
    "        agg = agg1.merge(agg2, how='inner', on='playlist_id')\n",
    "        agg = agg.merge(agg3, how='inner', on='playlist_id')\n",
    "        print(agg[:10])\n",
    "        \n",
    "    def create_uim(self, sparse_mode=\"coo\", create_testset = False, split = 0.8):\n",
    "        if sparse_mode.lower() == \"coo\" or sparse_mode.lower() == \"csr\":\n",
    "            self.UIM = sps.coo_matrix((self.list_interactions, (self.list_index_playlist, self.list_index_track)))\n",
    "            if create_testset:\n",
    "                self.split_traintest(train_test_split = split)\n",
    "            if sparse_mode.lower() == \"csr\" and create_testset != True:\n",
    "                self.UIM = self.UIM.tocsr()\n",
    "            elif sparse_mode.lower() == \"csr\" and create_testset == True:\n",
    "                self.UIM = self.UIM.tocsr()\n",
    "                self.UIM_train = self.UIM_train.tocsr()\n",
    "                self.UIM_test = self.UIM_test.tocsr()\n",
    "                \n",
    "        else:\n",
    "            raise NotImplementedError('Sparse mode not implemented'.format(sparse_mode))\n",
    "            \n",
    "    def split_traintest(self, train_test_split):\n",
    "        train_mask = np.random.choice([True,False], self.numInteractions, p=[train_test_split, 1-train_test_split])\n",
    "        test_mask = np.logical_not(train_mask)\n",
    "        self.UIM_train = sps.coo_matrix((self.list_interactions[train_mask], \n",
    "                                        (self.list_index_playlist[train_mask], \n",
    "                                         self.list_index_track[train_mask])))\n",
    "        self.UIM_test = sps.coo_matrix((self.list_interactions, (self.list_index_playlist, self.list_index_track)))\n",
    "        print(\"UIM successfully created in csr format.\")\n",
    "        \n",
    "    def create_icm(self):\n",
    "        tags_list = []\n",
    "        for index, row in self.df_tracks.iterrows():\n",
    "            if len(row['tags']) != 0:\n",
    "                for i in row['tags']:\n",
    "                    tags_list.append([row['index_track'], i, 1])\n",
    "        tags_list = pd.DataFrame(tags_list)\n",
    "        tags_list.columns = ['index_track', 'tag', 'interaction']\n",
    "        track_list = list(tags_list['index_track'])\n",
    "        tag_list = list(tags_list['tag'])\n",
    "        interaction_list = list(tags_list['interaction'])\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(tag_list)\n",
    "        taglist_icm = le.transform(tag_list)\n",
    "        self.ICM = sps.coo_matrix((interaction_list, (track_list, taglist_icm)))\n",
    "        self.ICM = self.ICM.tocsr()\n",
    "        print(\"ICM successfully created in csr format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BasicItemKNNRecommender(RecommenderSystem):\n",
    "       \n",
    "    def __str__(self):\n",
    "        return \"ItemKNN(similarity={},k={},shrinkage={})\".format(self.similarity_name, self.k, self.shrinkage)\n",
    "    \n",
    "    def fit(self, shrinkage=100, similarity='cosine'):\n",
    "        self.shrinkage = shrinkage\n",
    "        self.similarity_name = similarity\n",
    "        if similarity == 'cosine':\n",
    "            self.distance = Cosine(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'pearson':\n",
    "            self.distance = Pearson(shrinkage=self.shrinkage)\n",
    "        elif similarity == 'adj-cosine':\n",
    "            self.distance = AdjustedCosine(shrinkage=self.shrinkage)\n",
    "        else:\n",
    "            raise NotImplementedError('Distance {} not implemented'.format(similarity))\n",
    "        \n",
    "        self.create_uim(sparse_mode = 'csr')\n",
    "        self.create_icm()\n",
    "        \n",
    "        # ok\n",
    "        item_weights = self.distance.compute(self.ICM)\n",
    "        \n",
    "        item_weights = check_matrix(item_weights, 'csr') # nearly 10 times faster\n",
    "        print(\"Converted to csr\")\n",
    "        \n",
    "        self.W = item_weights\n",
    "        self.UIM_estm = self.UIM.dot(self.W)\n",
    "        print('UIM_estm calculated')\n",
    "\n",
    "    def recommend(self, at=5):\n",
    "        self.target_structure()\n",
    "        start_time = time.time()\n",
    "        for index, row in self.df_target.iterrows():          \n",
    "            #get row from URM_estm\n",
    "            estm = pd.DataFrame(self.UIM_estm[row['index_playlist'],:].T.toarray())\n",
    "            estm.reset_index(level=0, inplace=True)\n",
    "            estm.columns = ['index_track','pred']\n",
    "            # filter tracks which are already in the playlist, so they can't be recommended\n",
    "            estm = estm[-estm[\"index_track\"].isin(row['index_track'])]\n",
    "            # translate track index back to track_id\n",
    "            estm = estm.merge(self.df_track_id_unique, how='inner', on='index_track')\n",
    "            # filter on target track set\n",
    "            estm = estm[estm['track_id'].isin(self.list_target_tracks)]\n",
    "            estm = estm.sort_values('pred',ascending=False)\n",
    "            # print(estm)\n",
    "            count = 1\n",
    "            for index2, row2 in estm.iterrows():\n",
    "                # insert 5 top recommendations into dataframe\n",
    "                if count < (at + 1):\n",
    "                    row['recommend'].append(int(row2['track_id']))\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break\n",
    "        print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))\n",
    "\n",
    "def check_matrix(X, format='csc', dtype=np.float32):\n",
    "    if format == 'csc' and not isinstance(X, sps.csc_matrix):\n",
    "        return X.tocsc().astype(dtype)\n",
    "    elif format == 'csr' and not isinstance(X, sps.csr_matrix):\n",
    "        return X.tocsr().astype(dtype)\n",
    "    elif format == 'coo' and not isinstance(X, sps.coo_matrix):\n",
    "        return X.tocoo().astype(dtype)\n",
    "    elif format == 'dok' and not isinstance(X, sps.dok_matrix):\n",
    "        return X.todok().astype(dtype)\n",
    "    elif format == 'bsr' and not isinstance(X, sps.bsr_matrix):\n",
    "        return X.tobsr().astype(dtype)\n",
    "    elif format == 'dia' and not isinstance(X, sps.dia_matrix):\n",
    "        return X.todia().astype(dtype)\n",
    "    elif format == 'lil' and not isinstance(X, sps.lil_matrix):\n",
    "        return X.tolil().astype(dtype)\n",
    "    else:\n",
    "        return X.astype(dtype)\n",
    "    \n",
    "class ISimilarity(object):\n",
    "    \"\"\"Abstract interface for the similarity metrics\"\"\"\n",
    "\n",
    "    def __init__(self, shrinkage=10):\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "    def compute(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Cosine(ISimilarity):\n",
    "    def compute(self, X):\n",
    "        # convert to csc matrix for faster column-wise operations\n",
    "        X = check_matrix(X, 'csc', dtype=np.float32)\n",
    "\n",
    "        # 1) normalize the columns in X\n",
    "        # compute the column-wise norm\n",
    "        # NOTE: this is slightly inefficient. We must copy X to compute the column norms.\n",
    "        # A faster solution is to  normalize the matrix inplace with a Cython function.\n",
    "        Xsq = X.copy()\n",
    "        Xsq.data **= 2\n",
    "        norm = np.sqrt(Xsq.sum(axis=0))\n",
    "        norm = np.asarray(norm).ravel()\n",
    "        norm += 1e-6\n",
    "        # compute the number of non-zeros in each column\n",
    "        # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "        col_nnz = np.diff(X.indptr)\n",
    "        # then normalize the values in each column\n",
    "        X.data /= np.repeat(norm, col_nnz)\n",
    "        print(\"Normalized\")\n",
    "\n",
    "        # 2) compute the cosine similarity using the dot-product\n",
    "        dist = X * X.T\n",
    "        print(\"Computed\")\n",
    "        \n",
    "        # zero out diagonal values\n",
    "        dist = dist - sps.dia_matrix((dist.diagonal()[sp.newaxis, :], [0]), shape=dist.shape)\n",
    "        print(\"Removed diagonal\")\n",
    "        \n",
    "        # and apply the shrinkage\n",
    "        if self.shrinkage > 0:\n",
    "            dist = self.apply_shrinkage(X, dist)\n",
    "            print(\"Applied shrinkage\")    \n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def apply_shrinkage(self, X, dist):\n",
    "        # create an \"indicator\" version of X (i.e. replace values in X with ones)\n",
    "        X_ind = X.copy()\n",
    "        X_ind.data = np.ones_like(X_ind.data)\n",
    "        # compute the co-rated counts\n",
    "        co_counts = X_ind * X_ind.T\n",
    "        # remove the diagonal\n",
    "        co_counts = co_counts - sps.dia_matrix((co_counts.diagonal()[sp.newaxis, :], [0]), shape=co_counts.shape)\n",
    "        # compute the shrinkage factor as co_counts_ij / (co_counts_ij + shrinkage)\n",
    "        # then multiply dist with it\n",
    "        co_counts_shrink = co_counts.copy()\n",
    "        co_counts_shrink.data += self.shrinkage\n",
    "        co_counts.data /= co_counts_shrink.data\n",
    "        dist.data *= co_counts.data\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interactions (numInteractions): 1040522\n",
      "Size of df_target_playlists: (10000, 1)\n",
      "Size of df_target_tracks file: (32195, 1)\n",
      "Size of list_target_tracks file: 32195\n",
      "\n",
      "\n",
      "Track_id translated to indexes (df_track_id_unique): \n",
      "   index_track  track_id\n",
      "0            0   1048594\n",
      "1            1   2359314\n",
      "2            2   1835030\n",
      "3            3   3670041\n",
      "4            4   1048604\n",
      "\n",
      "\n",
      "Playlist_id translated to indexes (df_playlist_id_unique): \n",
      "   index_playlist  playlist_id\n",
      "0               0     10485762\n",
      "1               1      5767174\n",
      "2               2      7077894\n",
      "3               3     11534344\n",
      "4               4      1179658\n",
      "\n",
      "\n",
      "Number of Playlists: 45649\n",
      "Number of Tracks: 99999\n",
      "\n",
      "\n",
      "Interactions-file with IDs translated to indexes (saved in df_interactions): \n",
      "     playlist_id  track_id  interaction  index_playlist  index_track\n",
      "0           7569    162463            1            2425        62358\n",
      "87          7569    421750            1            2425        60999\n",
      "116         7569    795606            1            2425         3009\n",
      "125         7569   1195736            1            2425        55563\n",
      "195         7569   2227105            1            2425        49116\n",
      "\n",
      "\n",
      "Meta information about tracks read (df_tracks): \n",
      "   track_id  artist_id  duration  playcount   album  \\\n",
      "0   2972914        144    224000       49.0     [7]   \n",
      "1   2750239        246    157000        1.0     [8]   \n",
      "2   1550729        144    217000      554.0     [9]   \n",
      "3   2169950        144    207000      200.0     [9]   \n",
      "4   1903709        144    198000        5.0  [None]   \n",
      "\n",
      "                                     tags  index_track  \n",
      "0     [54087, 1757, 1718, 116712, 189631]        33328  \n",
      "1   [189631, 3424, 177424, 46208, 205245]        48728  \n",
      "2   [54087, 109806, 46869, 183258, 54337]        93035  \n",
      "3  [54087, 70618, 207003, 109806, 116712]        26668  \n",
      "4   [54087, 81223, 116712, 215342, 71028]        25248  \n",
      "(99999, 7)\n"
     ]
    }
   ],
   "source": [
    "cbf = BasicItemKNNRecommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICM successfully created in csr format.\n",
      "Normalized\n",
      "Computed\n",
      "Removed diagonal\n",
      "Converted to csr\n",
      "UIM_estm calculated\n"
     ]
    }
   ],
   "source": [
    "cbf.fit(shrinkage=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45649, 99999)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbf.UIM_estm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data structure for final prediction was created (df_target): \n",
      "   playlist_id                                           track_id  \\\n",
      "0         7614  [415173, 1384962, 1609224, 1614974, 1714787, 2...   \n",
      "1         7692  [88210, 266898, 280844, 302730, 384386, 551534...   \n",
      "2         7816  [126414, 245217, 513821, 611201, 767305, 84510...   \n",
      "3         8225  [13881, 261448, 311923, 500672, 676393, 906185...   \n",
      "4         8337  [451881, 1157460, 1205536, 1210884, 3131838, 3...   \n",
      "\n",
      "                                         index_track  index_playlist recommend  \n",
      "0  [58038, 27294, 13601, 15634, 53615, 16590, 739...            2447        []  \n",
      "1  [32883, 1416, 6262, 15120, 46326, 9696, 41315,...            2478        []  \n",
      "2  [47911, 94663, 96789, 32334, 93906, 21551, 971...            2519        []  \n",
      "3  [4523, 99812, 18243, 92598, 57550, 45423, 5806...            2679        []  \n",
      "4          [74517, 40765, 59706, 62219, 95577, 7177]            2715        []  \n",
      "(10000, 5)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-11759b50bca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-d3730299aa1e>\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, at)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m#get row from URM_estm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mestm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUIM_estm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index_playlist'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mestm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mestm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'index_track'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/moritzmeister/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                          copy=False)\n\u001b[1;32m    353\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataFrame constructor not properly called!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "cbf.recommend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b9946e2b2dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUIM_estm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index_playlist'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'row' is not defined"
     ]
    }
   ],
   "source": [
    "estm = pd.DataFrame(cbf.UIM_estm[row['index_playlist'],:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.032155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.008778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.020604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.006434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.015149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.003193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.003095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.005345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.003588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.002463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99969</th>\n",
       "      <td>0.000742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99970</th>\n",
       "      <td>0.007248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99971</th>\n",
       "      <td>0.002126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99972</th>\n",
       "      <td>0.003719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973</th>\n",
       "      <td>0.001750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99974</th>\n",
       "      <td>0.000745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99975</th>\n",
       "      <td>0.002358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99976</th>\n",
       "      <td>0.003772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99977</th>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99978</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99979</th>\n",
       "      <td>0.002743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99980</th>\n",
       "      <td>0.002215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99981</th>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99982</th>\n",
       "      <td>0.005366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99983</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>0.004507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>0.000588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>0.001045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>0.004982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>0.005298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>0.004223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <td>0.001683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>0.003664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>0.005618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.001348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.005549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.003163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.002537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99999 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0      0.006138\n",
       "1      0.001685\n",
       "2      0.021244\n",
       "3      0.000862\n",
       "4      0.001698\n",
       "5      0.000586\n",
       "6      0.002763\n",
       "7      0.000425\n",
       "8      0.005827\n",
       "9      0.000000\n",
       "10     0.000833\n",
       "11     0.032155\n",
       "12     0.003685\n",
       "13     0.008778\n",
       "14     0.002792\n",
       "15     0.020604\n",
       "16     0.006434\n",
       "17     0.000862\n",
       "18     0.000329\n",
       "19     0.015149\n",
       "20     0.002017\n",
       "21     0.001868\n",
       "22     0.003193\n",
       "23     0.003095\n",
       "24     0.000329\n",
       "25     0.000329\n",
       "26     0.005345\n",
       "27     0.003588\n",
       "28     0.000000\n",
       "29     0.002463\n",
       "...         ...\n",
       "99969  0.000742\n",
       "99970  0.007248\n",
       "99971  0.002126\n",
       "99972  0.003719\n",
       "99973  0.001750\n",
       "99974  0.000745\n",
       "99975  0.002358\n",
       "99976  0.003772\n",
       "99977  0.000460\n",
       "99978  0.000000\n",
       "99979  0.002743\n",
       "99980  0.002215\n",
       "99981  0.000281\n",
       "99982  0.005366\n",
       "99983  0.000000\n",
       "99984  0.004507\n",
       "99985  0.000588\n",
       "99986  0.001045\n",
       "99987  0.004982\n",
       "99988  0.005298\n",
       "99989  0.004223\n",
       "99990  0.000000\n",
       "99991  0.001683\n",
       "99992  0.000000\n",
       "99993  0.003664\n",
       "99994  0.005618\n",
       "99995  0.001348\n",
       "99996  0.005549\n",
       "99997  0.003163\n",
       "99998  0.002537\n",
       "\n",
       "[99999 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cbf.UIM_estm[0,:].T.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert integer scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ee546c77d606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUIM_estm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/moritzmeister/anaconda/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mtodense\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mshares\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \"\"\"\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/moritzmeister/anaconda/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;31m##############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/moritzmeister/anaconda/lib/python3.6/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         coo_todense(M, N, self.nnz, self.row, self.col, self.data,\n\u001b[0;32m--> 258\u001b[0;31m                     B.ravel('A'), fortran)\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert integer scalar"
     ]
    }
   ],
   "source": [
    "test = cbf.UIM_estm.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
